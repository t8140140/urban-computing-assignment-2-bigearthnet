{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as rx\n",
    "import rioxarray as rix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST FOR PLOTTING\n",
    "def norm_diff(x,y):\n",
    "    return (x-y)/(x+y)\n",
    "\n",
    "child = \"S2A_MSIL2A_20170701T093031_19_10\"\n",
    "\n",
    "def plot_folder(folder,rgb=True):\n",
    "    parent = \"data/\"\n",
    "    if rgb:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        blue = rix.open_rasterio(parent+f\"{folder}/{folder}_B02.tif\")\n",
    "        green = rix.open_rasterio(parent+f\"{folder}/{folder}_B03.tif\")\n",
    "        red = rix.open_rasterio(parent+f\"{folder}/{folder}_B04.tif\")\n",
    "        print(blue.attrs)\n",
    "        rgb_img = rx.concat([red, green, blue], dim='band')\n",
    "        # rgb_img = (red+green+blue).squeeze()\n",
    "        rgb_img.plot.imshow(robust=True)\n",
    "        plt.title(\"RGB image\")\n",
    "        plt.show()\n",
    "\n",
    "    elif not rgb:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        nir = rix.open_rasterio(parent+f\"{folder}/{folder}_B8A.tif\")\n",
    "        swir = rix.open_rasterio(parent+f\"{folder}/{folder}_B11.tif\")\n",
    "        avg_ndmi = np.mean(norm_diff(nir.values,swir.values).squeeze())\n",
    "        ndmi_img = norm_diff(nir,swir).squeeze()\n",
    "        print(avg_ndmi)\n",
    "        # plt.imshow(ndmi)\n",
    "        # plt.colorbar(label='Pixel Values')\n",
    "        # plt.title('GeoTIFF Image')\n",
    "        # plt.show()\n",
    "        ndmi_img.plot.imshow(robust=True)\n",
    "        plt.title(f\"NDMI image. Average NDMI:{avg_ndmi:.2f}\")\n",
    "        plt.show()\n",
    "\n",
    "# plot_folder(child,rgb=True)\n",
    "# plot_folder(child,rgb=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S2A_MSIL2A_20170701T093031_25_48' 'S2A_MSIL2A_20170701T093031_16_58'\n",
      " 'S2A_MSIL2A_20170701T093031_78_27' ... 'S2B_MSIL2A_20170801T095029_11_32'\n",
      " 'S2B_MSIL2A_20170906T101020_78_48' 'S2B_MSIL2A_20170802T092029_10_37']\n",
      "7343\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_folders(directory):\n",
    "    folders = np.array([d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))])\n",
    "    return folders\n",
    "all_folders = list_folders(\"data/\")\n",
    "print(all_folders)\n",
    "print(len(all_folders))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read GeoTIFF file\n",
    "def norm_diff(x,y):\n",
    "    try:\n",
    "        return (x-y)/(x+y)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# testchild = \"S2A_MSIL2A_20171101T094131_1_38\"\n",
    "\n",
    "\n",
    "def get_input_label(folder):\n",
    "    try:\n",
    "        base_path=f\"data/{folder}/{folder}\"\n",
    "\n",
    "        blue = rix.open_rasterio(f\"{base_path}_B02.tif\")\n",
    "        green = rix.open_rasterio(f\"{base_path}_B03.tif\")\n",
    "        red = rix.open_rasterio(f\"{base_path}_B04.tif\")     \n",
    "\n",
    "        rgb = np.concatenate([red.values,green.values,blue.values], axis=0)\n",
    "\n",
    "        # print(rgb)\n",
    "        nir = rix.open_rasterio(f\"{base_path}_B8A.tif\")\n",
    "        swir = rix.open_rasterio(f\"{base_path}_B11.tif\")\n",
    "\n",
    "        ndmi = norm_diff(nir.values.squeeze(),swir.values.squeeze())\n",
    "        label = np.mean(ndmi)\n",
    "        \n",
    "        return rgb, label\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/S2B_MSIL2A_20170802T092029_18_24/S2B_MSIL2A_20170802T092029_18_24_B03.tif: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/x8klff196fl8_dk1n2t0qbtc0000gn/T/ipykernel_11110/3558035866.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  return (x-y)/(x+y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/S2A_MSIL2A_20170613T101031_24_59/S2A_MSIL2A_20170613T101031_24_59_B02.tif: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/x8klff196fl8_dk1n2t0qbtc0000gn/T/ipykernel_11110/3558035866.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  return (x-y)/(x+y)\n",
      "/var/folders/68/x8klff196fl8_dk1n2t0qbtc0000gn/T/ipykernel_11110/3558035866.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  return (x-y)/(x+y)\n",
      "/var/folders/68/x8klff196fl8_dk1n2t0qbtc0000gn/T/ipykernel_11110/3558035866.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  return (x-y)/(x+y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/S2A_MSIL2A_20170701T093031_86_9/S2A_MSIL2A_20170701T093031_86_9_B03.tif: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "folders = all_folders.copy()\n",
    "\n",
    "input = np.zeros((len(folders), 3, 120, 120))\n",
    "labels = np.zeros((len(folders), 1))\n",
    "\n",
    "for j, folder in enumerate(folders):\n",
    "    rgb, label = get_input_label(folder)\n",
    "    # print(label)\n",
    "    input[j] = rgb\n",
    "    labels[j] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7343,)\n",
      "7343\n",
      "2881\n",
      "2881\n"
     ]
    }
   ],
   "source": [
    "# remove rows from label and input where label is nan or invalid (>1 or <-1)\n",
    "faulty_row = (np.isnan(labels) | (np.abs(labels)>1)).squeeze()\n",
    "print(folders.shape)\n",
    "labels_clean = labels[~faulty_row]\n",
    "input_clean = input[~faulty_row]\n",
    "folders_clean = folders[~faulty_row]\n",
    "# labels = np.clip(labels, -1, 1)\n",
    "print(len(labels))\n",
    "print(len(labels_clean))\n",
    "print(len(input_clean))\n",
    "# print(input[:3])\n",
    "# print(labels[:3])\n",
    "# print(input.shape)\n",
    "# np.save(\"arrays/clean_folders.npy\", folders_clean,)\n",
    "# np.save(\"arrays/clean_labels.npy\", labels_clean)\n",
    "# np.save(\"arrays/clean_input.npy\", input_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2881, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert labels to categorical\n",
    "labels_categorical = tf.keras.utils.to_categorical(labels_clean, num_classes=10)\n",
    "\n",
    "# Print the shape of the categorical labels\n",
    "print(labels_categorical.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start constructing network for RGB dimension (120,120,3)\n",
    "input_clean = input_clean.reshape(len(input_clean),120,120,3)\n",
    "input_shape = input_clean.shape\n",
    "\n",
    "# Example parameters, replace with your actual values\n",
    "# img_placeholder = tf.placeholder(tf.float32, input_shape)\n",
    "num_classes = 10  # Replace with your actual number of classes\n",
    "is_training = True  # Set to False for inference\n",
    "prediction_threshold = 0.5  # Set the threshold based on your needs\n",
    "\n",
    "# pre-trained network: pt\n",
    "input_t = tf.keras.Input(shape=(120,120,3))\n",
    "model_res = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=input_t,\n",
    "    input_shape=(120,120,3),\n",
    "    pooling=None,\n",
    "    classes=10,\n",
    ")\n",
    "\n",
    "# pretrained model\n",
    "model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Lambda(lambda image: tf.image.resize(image, (224, 224))))\n",
    "model.add(model_res)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "# I would not put a too complicated network on top to prevent overfitting\n",
    "# model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "# model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 543s 7s/step - loss: 1.8013 - accuracy: 0.4666 - val_loss: 48525.4961 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"logs/pt_fit/\"  # Choose a suitable directory\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# callback = tf.keras.callbacks.ModelCheckpoint(filepath='beNet50.h5', monitor='acc', mode=\"max\", save_best_only=True)\n",
    "checkpoint_path = \"weights/pt_weights.best.h5\"\n",
    "# default metric to compare whether it's \"best\" is loss\n",
    "model_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(input_clean, labels_categorical, epochs=1, batch_size=32, verbose=1, validation_split=0.2, callbacks=[tensorboard_callback,model_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parameters, replace with your actual values\n",
    "# img_placeholder = tf.placeholder(tf.float32, input_shape)\n",
    "num_classes = 10  # Replace with your actual number of classes\n",
    "is_training = True  # Set to False for inference\n",
    "prediction_threshold = 0.5  # Set the threshold based on your needs\n",
    "\n",
    "# same structure network but not pre-trained (initialised): init\n",
    "input_t = tf.keras.Input(shape=(120,120,3))\n",
    "model_res = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    input_tensor=input_t,\n",
    "    input_shape=(120,120,3),\n",
    "    pooling=None,\n",
    "    classes=10,\n",
    ")\n",
    "\n",
    "# pretrained model\n",
    "model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Lambda(lambda image: tf.image.resize(image, (224, 224))))\n",
    "model.add(model_res)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "72/72 [==============================] - 582s 8s/step - loss: 2.4358 - accuracy: 0.2309 - val_loss: 9.1046 - val_accuracy: 0.9168\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 479s 7s/step - loss: 1.3257 - accuracy: 0.6719 - val_loss: 0.7646 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "35/72 [=============>................] - ETA: 3:49 - loss: 0.6434 - accuracy: 0.9018"
     ]
    }
   ],
   "source": [
    "log_dir = \"logs/init_fit/\"  # Choose a suitable directory\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# callback = tf.keras.callbacks.ModelCheckpoint(filepath='beNet50.h5', monitor='acc', mode=\"max\", save_best_only=True)\n",
    "checkpoint_path = \"weights/init_weights.best.h5\"\n",
    "# default metric to compare whether it's \"best\" is loss\n",
    "model_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(input_clean, labels_categorical, epochs=10, batch_size=32, verbose=1, validation_split=0.2, callbacks=[tensorboard_callback,model_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parameters, replace with your actual values\n",
    "# img_placeholder = tf.placeholder(tf.float32, input_shape)\n",
    "num_classes = 10  # Replace with your actual number of classes\n",
    "is_training = False  # Set to False for inference\n",
    "prediction_threshold = 0.5  # Set the threshold based on your needs\n",
    "\n",
    "# pre-trained network with frozen ResNet weights (freeze): fr\n",
    "input_t = tf.keras.Input(shape=(120,120,3))\n",
    "model_res = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=input_t,\n",
    "    input_shape=(120,120,3),\n",
    "    pooling=None,\n",
    "    classes=10,\n",
    ")\n",
    "optional for not training the whole model\n",
    "for layer in model_res.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# pretrained model\n",
    "model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Lambda(lambda image: tf.image.resize(image, (224, 224))))\n",
    "model.add(model_res)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fr_fit/\"  # Choose a suitable directory\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# callback = tf.keras.callbacks.ModelCheckpoint(filepath='beNet50.h5', monitor='acc', mode=\"max\", save_best_only=True)\n",
    "checkpoint_path = \"weights/fr_weights.best.h5\"\n",
    "# default metric to compare whether it's \"best\" is loss\n",
    "model_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(input_clean, labels_categorical, epochs=10, batch_size=32, verbose=1, validation_split=0.2, callbacks=[tensorboard_callback,model_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urban",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
