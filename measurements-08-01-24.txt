Last login: Mon Jan  8 10:44:07 on ttys023
(holo) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % cd /Volumes/NO\ NAME/
(holo) lucajuliusbarbera@lucajb NO NAME % rm -rf data-short 
(holo) lucajuliusbarbera@lucajb NO NAME % cp -rf ~/urban/urban-computing-project-bigearthnet/arrays ./.
cp: /Users/lucajuliusbarbera/urban/urban-computing-project-bigearthnet/arrays/clean_input.npy: File too large
(holo) lucajuliusbarbera@lucajb NO NAME % cd ~
(holo) lucajuliusbarbera@lucajb ~ % cd ~/urban/urban-computing-project-bigearthnet 
(holo) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % git status
On branch main
Your branch is ahead of 'origin/main' by 1 commit.
  (use "git push" to publish your local commits)

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   network.ipynb
	modified:   new_network.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	new_network_cross.py

no changes added to commit (use "git add" and/or "git commit -a")
(holo) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % git add new_network.py new_network_cross.py 
(holo) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % git commit -m 'for PC'
[main 785a7e3] for PC
 2 files changed, 117 insertions(+), 1 deletion(-)
 create mode 100644 new_network_cross.py
(holo) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % git push
Enumerating objects: 10, done.
Counting objects: 100% (10/10), done.
Delta compression using up to 4 threads
Compressing objects: 100% (9/9), done.
Writing objects: 100% (9/9), 2.95 KiB | 2.95 MiB/s, done.
Total 9 (delta 6), reused 0 (delta 0), pack-reused 0
remote: Resolving deltas: 100% (6/6), completed with 1 local object.
To https://github.com/t8140140/urban-computing-project-bigearthnet.git
   090fcb0..785a7e3  main -> main
(holo) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % conda activate urban
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % python freeze_network.py 
2024-01-08 13:39:46.495098: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.3 when it was built against 1.14.2, this may cause problems
  _warn(("h5py is running against HDF5 {0} when it was built against {1}, "
Traceback (most recent call last):
  File "/Users/lucajuliusbarbera/urban/urban-computing-project-bigearthnet/freeze_network.py", line 21, in <module>
    input_clean = input_clean.numpy()
                  ^^^^^^^^^^^^^^^^^
AttributeError: 'numpy.ndarray' object has no attribute 'numpy'. Did you mean: 'dump'?
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % python freeze_network.py
2024-01-08 13:42:36.759164: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.3 when it was built against 1.14.2, this may cause problems
  _warn(("h5py is running against HDF5 {0} when it was built against {1}, "
[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 resnet50 (Functional)       (None, 4, 4, 2048)        23587712  
                                                                 
 flatten (Flatten)           (None, 32768)             0         
                                                                 
 batch_normalization (Batch  (None, 32768)             131072    
 Normalization)                                                  
                                                                 
 dense (Dense)               (None, 32)                1048608   
                                                                 
 dropout (Dropout)           (None, 32)                0         
                                                                 
 batch_normalization_1 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 dense_1 (Dense)             (None, 10)                330       
                                                                 
=================================================================
Total params: 24767850 (94.48 MB)
Trainable params: 1114538 (4.25 MB)
Non-trainable params: 23653312 (90.23 MB)
_________________________________________________________________
Epoch 1/2
381/381 [==============================] - 620s 2s/step - loss: 1.0213 - accuracy: 0.7269 - val_loss: 0.0318 - val_accuracy: 1.0000
Epoch 2/2
381/381 [==============================] - 567s 1s/step - loss: 0.0358 - accuracy: 0.9991 - val_loss: 0.0044 - val_accuracy: 1.0000
120/120 - 142s - loss: 0.0044 - accuracy: 1.0000 - 142s/epoch - 1s/step

Test Accuracy: 100.00%
596/596 [==============================] - 703s 1s/step
Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % python new_network.py   
2024-01-08 14:48:23.954695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.3 when it was built against 1.14.2, this may cause problems
  _warn(("h5py is running against HDF5 {0} when it was built against {1}, "
Arrays have been loaded...
Traceback (most recent call last):
  File "/Users/lucajuliusbarbera/urban/urban-computing-project-bigearthnet/new_network.py", line 24, in <module>
    input_train, input_test, labels_train, labels_test = train_test_split(
                                                         ^^^^^^^^^^^^^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 214, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/sklearn/model_selection/_split.py", line 2672, in train_test_split
    return list(
           ^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/sklearn/model_selection/_split.py", line 2674, in <genexpr>
    (_safe_indexing(a, train), _safe_indexing(a, test)) for a in arrays
     ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/sklearn/utils/__init__.py", line 355, in _safe_indexing
    return _array_indexing(X, indices, indices_dtype, axis=axis)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/sklearn/utils/__init__.py", line 184, in _array_indexing
    return array[key] if axis == 0 else array[:, key]
           ~~~~~^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/tensorflow/python/ops/array_ops.py", line 970, in _check_index
    raise TypeError(_SLICE_TYPE_ERROR + ", got {!r}".format(idx))
TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([18673, 17288,  8882, ...,  5390,   860, 15795])
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % mv small-import.py random_input_short.py
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % python random_input_short.py 
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % python new_network.py                   
2024-01-08 14:58:30.086419: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.3 when it was built against 1.14.2, this may cause problems
  _warn(("h5py is running against HDF5 {0} when it was built against {1}, "
Arrays have been loaded...
Train test split successful...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 118, 118, 32)      896       
                                                                 
 batch_normalization (Batch  (None, 118, 118, 32)      128       
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 118, 118, 32)      0         
                                                                 
 max_pooling2d (MaxPooling2  (None, 59, 59, 32)        0         
 D)                                                              
                                                                 
 conv2d_1 (Conv2D)           (None, 57, 57, 64)        18496     
                                                                 
 batch_normalization_1 (Bat  (None, 57, 57, 64)        256       
 chNormalization)                                                
                                                                 
 activation_1 (Activation)   (None, 57, 57, 64)        0         
                                                                 
 dropout (Dropout)           (None, 57, 57, 64)        0         
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 28, 28, 64)        0         
 g2D)                                                            
                                                                 
 flatten (Flatten)           (None, 50176)             0         
                                                                 
 dense (Dense)               (None, 32)                1605664   
                                                                 
 batch_normalization_2 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 activation_2 (Activation)   (None, 32)                0         
                                                                 
 dropout_1 (Dropout)         (None, 32)                0         
                                                                 
 dense_1 (Dense)             (None, 10)                330       
                                                                 
=================================================================
Total params: 1625898 (6.20 MB)
Trainable params: 1625642 (6.20 MB)
Non-trainable params: 256 (1.00 KB)
_________________________________________________________________
Epoch 1/2
381/381 [==============================] - 303s 787ms/step - loss: 0.5743 - accuracy: 0.8769 - val_loss: 0.0322 - val_accuracy: 1.0000
Epoch 2/2
381/381 [==============================] - 323s 847ms/step - loss: 0.0486 - accuracy: 0.9996 - val_loss: 0.0020 - val_accuracy: 1.0000
120/120 - 26s - loss: 0.0019 - accuracy: 1.0000 - 26s/epoch - 216ms/step

Test Accuracy: 100.00%
596/596 [==============================] - 120s 200ms/step
Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % python init_network.py 
2024-01-08 15:25:13.560490: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.3 when it was built against 1.14.2, this may cause problems
  _warn(("h5py is running against HDF5 {0} when it was built against {1}, "
Arrays have been loaded...
Train test split successful...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 resnet50 (Functional)       (None, 4, 4, 2048)        23587712  
                                                                 
 flatten (Flatten)           (None, 32768)             0         
                                                                 
 batch_normalization (Batch  (None, 32768)             131072    
 Normalization)                                                  
                                                                 
 dense (Dense)               (None, 32)                1048608   
                                                                 
 dropout (Dropout)           (None, 32)                0         
                                                                 
 batch_normalization_1 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 dense_1 (Dense)             (None, 10)                330       
                                                                 
=================================================================
Total params: 24767850 (94.48 MB)
Trainable params: 24649130 (94.03 MB)
Non-trainable params: 118720 (463.75 KB)
_________________________________________________________________
init_network at 20240108_153029.
Epoch 1/5
381/381 [==============================] - 2287s 6s/step - loss: 1.0125 - accuracy: 0.7574 - val_loss: 1.1293 - val_accuracy: 0.8907
Epoch 2/5
381/381 [==============================] - 2275s 6s/step - loss: 0.0416 - accuracy: 0.9975 - val_loss: 0.0046 - val_accuracy: 1.0000
Epoch 3/5
170/381 [============>.................] - ETA: 21:55 - loss: 0.0115 - accuracy: 0.9996^CTraceback (most recent call last):
  File "/Users/lucajuliusbarbera/urban/urban-computing-project-bigearthnet/init_network.py", line 66, in <module>
    history = model.fit(
              ^^^^^^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/keras/src/engine/training.py", line 1783, in fit
    tmp_logs = self.train_function(iterator)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 831, in __call__
    result = self._call(*args, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 867, in _call
    return tracing_compilation.call_function(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py", line 139, in call_function
    return function._call_flat(  # pylint: disable=protected-access
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py", line 1264, in _call_flat
    return self._inference_function.flat_call(args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py", line 217, in flat_call
    flat_outputs = self(*args)
                   ^^^^^^^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py", line 252, in __call__
    outputs = self._bound_context.call_function(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/tensorflow/python/eager/context.py", line 1479, in call_function
    outputs = execute.execute(
              ^^^^^^^^^^^^^^^^
  File "/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % top
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % top
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % kill 45326
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % python
Python 3.11.0 | packaged by conda-forge | (main, Jan 15 2023, 05:44:48) [Clang 14.0.6 ] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>> 
KeyboardInterrupt
>>> 
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % python 5
python: can't open file '/Users/lucajuliusbarbera/urban/urban-computing-project-bigearthnet/5': [Errno 2] No such file or directory
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % python new_network.py 1000
2024-01-08 17:32:45.097334: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.3 when it was built against 1.14.2, this may cause problems
  _warn(("h5py is running against HDF5 {0} when it was built against {1}, "
Arrays have been loaded...
Train test split successful...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 118, 118, 32)      896       
                                                                 
 batch_normalization (Batch  (None, 118, 118, 32)      128       
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 118, 118, 32)      0         
                                                                 
 max_pooling2d (MaxPooling2  (None, 59, 59, 32)        0         
 D)                                                              
                                                                 
 conv2d_1 (Conv2D)           (None, 57, 57, 64)        18496     
                                                                 
 batch_normalization_1 (Bat  (None, 57, 57, 64)        256       
 chNormalization)                                                
                                                                 
 activation_1 (Activation)   (None, 57, 57, 64)        0         
                                                                 
 dropout (Dropout)           (None, 57, 57, 64)        0         
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 28, 28, 64)        0         
 g2D)                                                            
                                                                 
 flatten (Flatten)           (None, 50176)             0         
                                                                 
 dense (Dense)               (None, 32)                1605664   
                                                                 
 batch_normalization_2 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 activation_2 (Activation)   (None, 32)                0         
                                                                 
 dropout_1 (Dropout)         (None, 32)                0         
                                                                 
 dense_1 (Dense)             (None, 10)                330       
                                                                 
=================================================================
Total params: 1625898 (6.20 MB)
Trainable params: 1625642 (6.20 MB)
Non-trainable params: 256 (1.00 KB)
_________________________________________________________________
new_network at 20240108_173302.
Epoch 1/2
20/20 [==============================] - 14s 631ms/step - loss: 2.8552 - accuracy: 0.1187 - val_loss: 10.6621 - val_accuracy: 0.0375
Epoch 2/2
20/20 [==============================] - 12s 619ms/step - loss: 2.2237 - accuracy: 0.3469 - val_loss: 2.8270 - val_accuracy: 0.5312
7/7 - 1s - loss: 2.7938 - accuracy: 0.5650 - 1s/epoch - 179ms/step

Test Accuracy: 56.50%
32/32 [==============================] - 5s 160ms/step
/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Precision: 1.0000, Recall: 0.5760, F1 Score: 0.7310
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % git add .
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % git commit -m 'added different size database to new_network experiment' 
[main 2d0f95a] added different size database to new_network experiment
 83 files changed, 225 insertions(+), 18027 deletions(-)
 delete mode 160000 bigearthnet-models-tf
 delete mode 100644 models/K-BranchCNN.py
 delete mode 100644 models/README.md
 delete mode 100644 models/ResNet101.py
 delete mode 100644 models/ResNet152.py
 delete mode 100644 models/ResNet50.py
 delete mode 100644 models/VGG16.py
 delete mode 100644 models/VGG19.py
 delete mode 100644 models/__init__.py
 delete mode 100644 models/main_model.py
 delete mode 100644 nets/__init__.py
 delete mode 100644 nets/__pycache__/resnet_utils.cpython-39.pyc
 delete mode 100644 nets/alexnet.py
 delete mode 100644 nets/alexnet_test.py
 delete mode 100644 nets/cifarnet.py
 delete mode 100644 nets/cyclegan.py
 delete mode 100644 nets/cyclegan_test.py
 delete mode 100644 nets/dcgan.py
 delete mode 100644 nets/dcgan_test.py
 delete mode 100644 nets/i3d.py
 delete mode 100644 nets/i3d_test.py
 delete mode 100644 nets/i3d_utils.py
 delete mode 100644 nets/inception.py
 delete mode 100644 nets/inception_resnet_v2.py
 delete mode 100644 nets/inception_resnet_v2_test.py
 delete mode 100644 nets/inception_utils.py
 delete mode 100644 nets/inception_v1.py
 delete mode 100644 nets/inception_v1_test.py
 delete mode 100644 nets/inception_v2.py
 delete mode 100644 nets/inception_v2_test.py
 delete mode 100644 nets/inception_v3.py
 delete mode 100644 nets/inception_v3_test.py
 delete mode 100644 nets/inception_v4.py
 delete mode 100644 nets/inception_v4_test.py
 delete mode 100644 nets/lenet.py
 delete mode 100644 nets/mobilenet/README.md
 delete mode 100644 nets/mobilenet/__init__.py
 delete mode 100644 nets/mobilenet/conv_blocks.py
 delete mode 100644 nets/mobilenet/g3doc/edgetpu_latency.png
 delete mode 100644 nets/mobilenet/g3doc/latency_pixel1.png
 delete mode 100644 nets/mobilenet/g3doc/madds_top1_accuracy.png
 delete mode 100644 nets/mobilenet/mnet_v1_vs_v2_pixel1_latency.png
 delete mode 100644 nets/mobilenet/mobilenet.py
 delete mode 100644 nets/mobilenet/mobilenet_example.ipynb
 delete mode 100644 nets/mobilenet/mobilenet_v2.py
 delete mode 100644 nets/mobilenet/mobilenet_v2_test.py
 delete mode 100644 nets/mobilenet/mobilenet_v3.py
 delete mode 100644 nets/mobilenet/mobilenet_v3_test.py
 delete mode 100644 nets/mobilenet_v1.md
 delete mode 100644 nets/mobilenet_v1.png
 delete mode 100644 nets/mobilenet_v1.py
 delete mode 100644 nets/mobilenet_v1_eval.py
 delete mode 100644 nets/mobilenet_v1_test.py
 delete mode 100644 nets/mobilenet_v1_train.py
 delete mode 100644 nets/nasnet/README.md
 delete mode 100644 nets/nasnet/__init__.py
 delete mode 100644 nets/nasnet/nasnet.py
 delete mode 100644 nets/nasnet/nasnet_test.py
 delete mode 100644 nets/nasnet/nasnet_utils.py
 delete mode 100644 nets/nasnet/nasnet_utils_test.py
 delete mode 100644 nets/nasnet/pnasnet.py
 delete mode 100644 nets/nasnet/pnasnet_test.py
 delete mode 100644 nets/nets_factory.py
 delete mode 100644 nets/nets_factory_test.py
 delete mode 100644 nets/overfeat.py
 delete mode 100644 nets/overfeat_test.py
 delete mode 100644 nets/pix2pix.py
 delete mode 100644 nets/pix2pix_test.py
 delete mode 100644 nets/post_training_quantization.py
 delete mode 100644 nets/resnet_utils.py
 delete mode 100644 nets/resnet_v1.py
 delete mode 100644 nets/resnet_v1_test.py
 delete mode 100644 nets/resnet_v2.py
 delete mode 100644 nets/resnet_v2_test.py
 delete mode 100644 nets/s3dg.py
 delete mode 100644 nets/s3dg_test.py
 delete mode 100644 nets/vgg.py
 delete mode 100644 nets/vgg_test.py
 create mode 100644 random_input_short.py
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % git push
Enumerating objects: 12, done.
Counting objects: 100% (12/12), done.
Delta compression using up to 4 threads
Compressing objects: 100% (7/7), done.
Writing objects: 100% (7/7), 2.51 KiB | 429.00 KiB/s, done.
Total 7 (delta 4), reused 0 (delta 0), pack-reused 0
remote: Resolving deltas: 100% (4/4), completed with 2 local objects.
To https://github.com/t8140140/urban-computing-project-bigearthnet.git
   785a7e3..2d0f95a  main -> main
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % python new_network.py 2000
2024-01-08 17:36:31.163781: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.3 when it was built against 1.14.2, this may cause problems
  _warn(("h5py is running against HDF5 {0} when it was built against {1}, "
Arrays have been loaded...
Train test split successful...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 118, 118, 32)      896       
                                                                 
 batch_normalization (Batch  (None, 118, 118, 32)      128       
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 118, 118, 32)      0         
                                                                 
 max_pooling2d (MaxPooling2  (None, 59, 59, 32)        0         
 D)                                                              
                                                                 
 conv2d_1 (Conv2D)           (None, 57, 57, 64)        18496     
                                                                 
 batch_normalization_1 (Bat  (None, 57, 57, 64)        256       
 chNormalization)                                                
                                                                 
 activation_1 (Activation)   (None, 57, 57, 64)        0         
                                                                 
 dropout (Dropout)           (None, 57, 57, 64)        0         
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 28, 28, 64)        0         
 g2D)                                                            
                                                                 
 flatten (Flatten)           (None, 50176)             0         
                                                                 
 dense (Dense)               (None, 32)                1605664   
                                                                 
 batch_normalization_2 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 activation_2 (Activation)   (None, 32)                0         
                                                                 
 dropout_1 (Dropout)         (None, 32)                0         
                                                                 
 dense_1 (Dense)             (None, 10)                330       
                                                                 
=================================================================
Total params: 1625898 (6.20 MB)
Trainable params: 1625642 (6.20 MB)
Non-trainable params: 256 (1.00 KB)
_________________________________________________________________
new_network at 20240108_173649.
Epoch 1/2
40/40 [==============================] - 30s 701ms/step - loss: 2.2676 - accuracy: 0.3172 - val_loss: 2.6225 - val_accuracy: 0.4875
Epoch 2/2
40/40 [==============================] - 27s 683ms/step - loss: 1.2577 - accuracy: 0.7047 - val_loss: 1.1798 - val_accuracy: 0.7750
13/13 - 2s - loss: 1.0592 - accuracy: 0.8350 - 2s/epoch - 182ms/step

Test Accuracy: 83.50%
63/63 [==============================] - 11s 171ms/step
/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Precision: 1.0000, Recall: 0.7990, F1 Score: 0.8883
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % python new_network.py 5000
2024-01-08 17:39:00.030541: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.3 when it was built against 1.14.2, this may cause problems
  _warn(("h5py is running against HDF5 {0} when it was built against {1}, "
Arrays have been loaded...
Train test split successful...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 118, 118, 32)      896       
                                                                 
 batch_normalization (Batch  (None, 118, 118, 32)      128       
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 118, 118, 32)      0         
                                                                 
 max_pooling2d (MaxPooling2  (None, 59, 59, 32)        0         
 D)                                                              
                                                                 
 conv2d_1 (Conv2D)           (None, 57, 57, 64)        18496     
                                                                 
 batch_normalization_1 (Bat  (None, 57, 57, 64)        256       
 chNormalization)                                                
                                                                 
 activation_1 (Activation)   (None, 57, 57, 64)        0         
                                                                 
 dropout (Dropout)           (None, 57, 57, 64)        0         
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 28, 28, 64)        0         
 g2D)                                                            
                                                                 
 flatten (Flatten)           (None, 50176)             0         
                                                                 
 dense (Dense)               (None, 32)                1605664   
                                                                 
 batch_normalization_2 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 activation_2 (Activation)   (None, 32)                0         
                                                                 
 dropout_1 (Dropout)         (None, 32)                0         
                                                                 
 dense_1 (Dense)             (None, 10)                330       
                                                                 
=================================================================
Total params: 1625898 (6.20 MB)
Trainable params: 1625642 (6.20 MB)
Non-trainable params: 256 (1.00 KB)
_________________________________________________________________
new_network at 20240108_173924.
Epoch 1/2
100/100 [==============================] - 68s 667ms/step - loss: 1.2532 - accuracy: 0.6375 - val_loss: 1.1000 - val_accuracy: 0.9300
Epoch 2/2
100/100 [==============================] - 64s 632ms/step - loss: 0.3249 - accuracy: 0.9781 - val_loss: 0.2178 - val_accuracy: 1.0000
32/32 - 6s - loss: 0.2008 - accuracy: 1.0000 - 6s/epoch - 174ms/step

Test Accuracy: 100.00%
157/157 [==============================] - 27s 166ms/step
Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % python new_network.py 10000
2024-01-08 17:42:57.485461: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/Users/lucajuliusbarbera/opt/miniconda3/envs/urban/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.3 when it was built against 1.14.2, this may cause problems
  _warn(("h5py is running against HDF5 {0} when it was built against {1}, "
Arrays have been loaded...
Train test split successful...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 118, 118, 32)      896       
                                                                 
 batch_normalization (Batch  (None, 118, 118, 32)      128       
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 118, 118, 32)      0         
                                                                 
 max_pooling2d (MaxPooling2  (None, 59, 59, 32)        0         
 D)                                                              
                                                                 
 conv2d_1 (Conv2D)           (None, 57, 57, 64)        18496     
                                                                 
 batch_normalization_1 (Bat  (None, 57, 57, 64)        256       
 chNormalization)                                                
                                                                 
 activation_1 (Activation)   (None, 57, 57, 64)        0         
                                                                 
 dropout (Dropout)           (None, 57, 57, 64)        0         
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 28, 28, 64)        0         
 g2D)                                                            
                                                                 
 flatten (Flatten)           (None, 50176)             0         
                                                                 
 dense (Dense)               (None, 32)                1605664   
                                                                 
 batch_normalization_2 (Bat  (None, 32)                128       
 chNormalization)                                                
                                                                 
 activation_2 (Activation)   (None, 32)                0         
                                                                 
 dropout_1 (Dropout)         (None, 32)                0         
                                                                 
 dense_1 (Dense)             (None, 10)                330       
                                                                 
=================================================================
Total params: 1625898 (6.20 MB)
Trainable params: 1625642 (6.20 MB)
Non-trainable params: 256 (1.00 KB)
_________________________________________________________________
new_network at 20240108_174408.
Epoch 1/2
200/200 [==============================] - 146s 722ms/step - loss: 1.0477 - accuracy: 0.7519 - val_loss: 0.2861 - val_accuracy: 1.0000
Epoch 2/2
200/200 [==============================] - 128s 640ms/step - loss: 0.1370 - accuracy: 0.9986 - val_loss: 0.0188 - val_accuracy: 1.0000
63/63 - 11s - loss: 0.0192 - accuracy: 1.0000 - 11s/epoch - 174ms/step

Test Accuracy: 100.00%
313/313 [==============================] - 57s 180ms/step
Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000
(urban) lucajuliusbarbera@lucajb urban-computing-project-bigearthnet % 
